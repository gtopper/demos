{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projects and automated ML pipeline\n",
    "\n",
    "This notebook demonstrates how to work with projects, source control (git), and automating the ML pipeline.\n",
    "\n",
    "Make sure you went over the basics in MLRun [**Quick Start Tutorial**](./01-mlrun-basics.html).\n",
    "\n",
    "MLRun Project is a container for all your work on a particular activity: all the associated code, [functions](https://docs.mlrun.org/en/latest/runtimes/functions.html), [jobs](https://docs.mlrun.org/en/latest/concepts/submitting-tasks-jobs-to-functions.html), [workflows](https://docs.mlrun.org/en/latest/concepts/workflow-overview.html), data, models, and [artifacts](https://docs.mlrun.org/en/latest/store/artifacts.html). Projects can be mapped to `git` repositories to enable versioning, collaboration, and [CI/CD](../projects/ci-integration.html).\n",
    "\n",
    "You can create project definitions using the SDK or a yaml file and store those in the MLRun DB, a file, or an archive.\n",
    "Once the project is loaded you can run jobs/workflows that refer to any project element by name, allowing separation between configuration and code. See [load projects](../projects/load-project.html) for details.\n",
    "\n",
    "Projects contain `workflows` that execute the registered functions in a sequence/graph (DAG), and that can reference project parameters, secrets and artifacts by name. MLRun currently supports two workflow engines, `local` (for simple tasks) and [Kubeflow Pipelines](https://www.kubeflow.org/docs/pipelines/pipelines-quickstart/) (for more complex/advanced tasks). MLRun also supports a real-time workflow engine (see [online serving pipelines (graphs)](https://docs.mlrun.org/en/latest/serving/serving-graph.html). \n",
    "\n",
    "An ML Engineer can gather the different functions created by the data engineer and data scientist and create this automated pipeline.\n",
    "\n",
    "Tutorial steps:\n",
    "- [**Set up the project and functions**](#project)\n",
    "- [**Work with GIT and archives**](#archives)\n",
    "- [**Build and run automated ML pipelines and CI/CD**](#pipeline)\n",
    "- [**Test the deployed model endpoint**](#test-model)\n",
    "\n",
    "## MLRun installation and configuration\n",
    "\n",
    "Before running this notebook make sure the `mlrun` package is installed (`pip install mlrun`) and that you have configured the access to MLRun service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install MLRun if not installed, run this only once (restart the notebook after the install !!!)\n",
    "%pip install mlrun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"project\"></a>\n",
    "## Set up the project and functions\n",
    "\n",
    "**Get or create a project**\n",
    "\n",
    "There are three ways to create/load [**MLRun projects**](https://docs.mlrun.org/en/latest/projects/project.html):\n",
    "* `mlrun.projects.new_project()`  &mdash; Create a new MLRun project and optionally load it from a yaml/zip/git template.\n",
    "* `mlrun.projects.load_project()` &mdash; Load a project from a context directory or remote git/zip/tar archive.\n",
    "* `mlrun.projects.get_or_create_project()` &mdash; Load a project from the MLRun DB if it exists, or from a specified \n",
    "  context/archive. \n",
    "\n",
    "Projects refer to a `context` directory that holds all the project code and configuration. The `context` dir is \n",
    "usually mapped to a `git` repository and/or to an IDE (PyCharm, VSCode, etc.) project.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-12-17 19:56:01,846 [info] loaded project tutorial from MLRun DB\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "project = mlrun.get_or_create_project(\"tutorial\", context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-setting-up-project\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register project functions\n",
    "\n",
    "To run workflows, you must save the definitions for the functions in the project so that function objects are initialized \n",
    "automatically when you load a project or when running a project version in automated CI/CD workflows. In addition, you might want to set/register other project attributes such as global parameters, secrets, and data.\n",
    "\n",
    "Functions are registered using the `set_function()` command, where you can specify the code, requirements, image, etc. \n",
    "Functions can be created from a single code/notebook file or have access to the entire project context directory. (By adding the `with_repo=True` flag, it guarantees that the project context is cloned into the function runtime environment).\n",
    "\n",
    "Function registration examples:\n",
    "\n",
    "```python\n",
    "    # Example: register a notebook file as a function\n",
    "    project.set_function('mynb.ipynb', name='test-function', image=\"mlrun/mlrun\", handler=\"run_test\")\n",
    "\n",
    "    # Define a job (batch) function that uses code/libs from the project repo\n",
    "    project.set_function(\n",
    "        name=\"myjob\", handler=\"my_module.job_handler\",\n",
    "        image=\"mlrun/mlrun\", kind=\"job\", with_repo=True,\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function code**\n",
    "\n",
    "Run the following cell to generate the data prep file (or copy it manually):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting data-prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data-prep.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import mlrun\n",
    "\n",
    "\n",
    "@mlrun.handler(outputs=[\"dataset\", \"label_column\"])\n",
    "def breast_cancer_generator():\n",
    "    \"\"\"\n",
    "    A function that generates the breast cancer dataset\n",
    "    \"\"\"\n",
    "    breast_cancer = load_breast_cancer()\n",
    "    breast_cancer_dataset = pd.DataFrame(\n",
    "        data=breast_cancer.data, columns=breast_cancer.feature_names\n",
    "    )\n",
    "    breast_cancer_labels = pd.DataFrame(data=breast_cancer.target, columns=[\"label\"])\n",
    "    breast_cancer_dataset = pd.concat(\n",
    "        [breast_cancer_dataset, breast_cancer_labels], axis=1\n",
    "    )\n",
    "\n",
    "    return breast_cancer_dataset, \"label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Register the function above in the project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.kubejob.KubejobRuntime at 0x7fa2240f0190>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"data-prep.py\", name=\"data-prep\", kind=\"job\", image=\"mlrun/mlrun\", handler=\"breast_cancer_generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Register additional project objects and metadata**\n",
    "\n",
    "You can define other objects (workflows, artifacts, secrets) and parameters in the project and use them in your functions, for example:\n",
    "\n",
    "```python\n",
    "    # Register a simple named artifact in the project (to be used in workflows)  \n",
    "    data_url = 'https://s3.wasabisys.com/iguazio/data/iris/iris.data.raw.csv'\n",
    "    project.set_artifact('data', target_path=data_url)\n",
    "\n",
    "    # Add a multi-stage workflow (./workflow.py) to the project with the name 'main' and save the project \n",
    "    project.set_workflow('main', \"./workflow.py\")\n",
    "    \n",
    "    # Read env vars from dict or file and set as project secrets\n",
    "    project.set_secrets({\"SECRET1\": \"value\"})\n",
    "    project.set_secrets(file_path=\"secrets.env\")\n",
    "    \n",
    "    project.spec.params = {\"x\": 5}\n",
    "```\n",
    "\n",
    "**Save the project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7fa200796890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the project in the db (and into the project.yaml file)\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you save the project it stores the project definitions in the `project.yaml`. This allows reconstructing the project in a remote cluster or a CI/CD system. \n",
    "\n",
    "See the generated project file: [**project.yaml**](project.yaml).\n",
    "\n",
    "<a id=\"archives\"></a>\n",
    "## Work with GIT and archives\n",
    "\n",
    "### Push the project code/metadata into an archive\n",
    "\n",
    "Use standard git commands to push the current project tree into a git archive. Make sure you `.save()` the project before pushing it.\n",
    "\n",
    "    git remote add origin <server>\n",
    "    git commit -m \"Commit message\"\n",
    "    git push origin master\n",
    "\n",
    "Alternatively, you can use MLRun SDK calls:\n",
    "- `project.create_remote(git_uri, branch=branch)` &mdash; to register the remote Git path\n",
    "- `project.push()` &mdash; save the project state and commit/push updates to the remote git repo\n",
    "\n",
    "You can also save the project content and metadata into a local or remote `.zip` archive, for example: \n",
    "\n",
    "    project.export(\"../archive1.zip\")\n",
    "    project.export(\"s3://my-bucket/archive1.zip\")\n",
    "    project.export(f\"v3io://projects/{project.name}/archive1.zip\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load'></a>\n",
    "### Load a project from local/remote archive \n",
    "\n",
    "The project metadata and context (code and configuration) can be loaded and initialized using the {py:meth}`~mlrun.projects.load_project` method.\n",
    "When `url` (of the git/zip/tar) is specified, it clones a remote repo into the local `context` dir.\n",
    "\n",
    "    # Load the project and run the 'main' workflow\n",
    "    project = load_project(context=\"./\", name=\"myproj\", url=\"git://github.com/mlrun/project-archive.git\")\n",
    "    project.run(\"main\", arguments={'data': data_url})\n",
    "\n",
    "Projects can also be loaded and executed using the CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-archive.git\" .\n",
    "    mlrun project -r main -w -a data=<data-url> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the project in the current context dir\n",
    "project = mlrun.load_project(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "## Build and run automated ML pipelines and CI/CD\n",
    "\n",
    "A pipeline is created by running an MLRun **\"workflow\"**.\n",
    "The following code defines a workflow and writes it to a file in your local directory, with the file name **workflow.py**.\n",
    "The workflow describes a directed acyclic graph (DAG) which is executed using the `local`, `remote`, or `kubeflow` engines.\n",
    "\n",
    "See [running a multi-stage workflow](https://docs.mlrun.org/en/latest/concepts/workflow-overview.html).\n",
    "The defined pipeline includes the following steps:\n",
    "\n",
    "- Generate/prepare the data (`ingest`).\n",
    "- Train and the model (`train`).\n",
    "- Deploy the model as a real-time serverless function (`serving`).\n",
    "\n",
    "```{admonition} Note\n",
    "A pipeline can also include continuous build integration and deployment (CI/CD) steps, such as building container images and deploying models.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./workflow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './workflow.py'\n",
    "\n",
    "from kfp import dsl\n",
    "import mlrun\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(name=\"breast-cancer-demo\")\n",
    "def pipeline(model_name=\"cancer-classifier\"):\n",
    "    # Run the ingestion function with the new image and params\n",
    "    ingest = mlrun.run_function(\n",
    "        \"data-prep\",\n",
    "        name=\"get-data\",\n",
    "        outputs=[\"dataset\"],\n",
    "    )\n",
    "\n",
    "    # Train a model using the auto_trainer hub function\n",
    "    train = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        inputs={\"dataset\": ingest.outputs[\"dataset\"]},\n",
    "        params = {\n",
    "            \"model_class\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"train_test_split_size\": 0.2,\n",
    "            \"label_columns\": \"label\",\n",
    "            \"model_name\": model_name,\n",
    "        }, \n",
    "        handler='train',\n",
    "        outputs=[\"model\"],\n",
    "    )\n",
    "\n",
    "    # Deploy the trained model as a serverless function\n",
    "    serving_fn = mlrun.new_function(\"serving\", image=\"mlrun/mlrun\", kind=\"serving\")\n",
    "    serving_fn.with_code(body=\" \")\n",
    "    mlrun.deploy_function(\n",
    "        serving_fn,\n",
    "        models=[\n",
    "            {\n",
    "                \"key\": model_name,\n",
    "                \"model_path\": train.outputs[\"model\"],\n",
    "                \"class_name\": 'mlrun.frameworks.sklearn.SklearnModelServer',\n",
    "            }\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-tutorial-4-step-register-workflow\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>Pipeline running (id=0d7769d2-5e2a-4ee5-95b2-7bc1713ee23d), <a href=\"https://dashboard.default-tenant.app.vmdev94.lab.iguazeng.com/mlprojects/tutorial-dani/jobs/monitor-workflows/workflow/0d7769d2-5e2a-4ee5-95b2-7bc1713ee23d\" target=\"_blank\"><b>click here</b></a> to view the details in MLRun UI</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"191pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 191.28 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-184 187.2837,-184 187.2837,4 -4,4\"/>\n",
       "<!-- breast&#45;cancer&#45;demo&#45;kg5ss&#45;3060750900 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>breast&#45;cancer&#45;demo&#45;kg5ss&#45;3060750900</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"91.6419\" cy=\"-162\" rx=\"49.2915\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"91.6419\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">get&#45;data</text>\n",
       "</g>\n",
       "<!-- breast&#45;cancer&#45;demo&#45;kg5ss&#45;3638193967 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>breast&#45;cancer&#45;demo&#45;kg5ss&#45;3638193967</title>\n",
       "<ellipse fill=\"#00ff00\" stroke=\"#000000\" cx=\"91.6419\" cy=\"-90\" rx=\"91.784\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"91.6419\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">auto&#45;trainer&#45;train</text>\n",
       "</g>\n",
       "<!-- breast&#45;cancer&#45;demo&#45;kg5ss&#45;3060750900&#45;&gt;breast&#45;cancer&#45;demo&#45;kg5ss&#45;3638193967 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>breast&#45;cancer&#45;demo&#45;kg5ss&#45;3060750900&#45;&gt;breast&#45;cancer&#45;demo&#45;kg5ss&#45;3638193967</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M91.6419,-143.8314C91.6419,-136.131 91.6419,-126.9743 91.6419,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.142,-118.4132 91.6419,-108.4133 88.142,-118.4133 95.142,-118.4132\"/>\n",
       "</g>\n",
       "<!-- breast&#45;cancer&#45;demo&#45;kg5ss&#45;3659454445 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>breast&#45;cancer&#45;demo&#45;kg5ss&#45;3659454445</title>\n",
       "<polygon fill=\"#00ff00\" stroke=\"#000000\" points=\"152.6419,-36 34.6419,-36 30.6419,-32 30.6419,0 148.6419,0 152.6419,-4 152.6419,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"148.6419,-32 30.6419,-32 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"148.6419,-32 148.6419,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"148.6419,-32 152.6419,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"91.6419\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">deploy&#45;serving</text>\n",
       "</g>\n",
       "<!-- breast&#45;cancer&#45;demo&#45;kg5ss&#45;3638193967&#45;&gt;breast&#45;cancer&#45;demo&#45;kg5ss&#45;3659454445 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>breast&#45;cancer&#45;demo&#45;kg5ss&#45;3638193967&#45;&gt;breast&#45;cancer&#45;demo&#45;kg5ss&#45;3659454445</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M91.6419,-71.8314C91.6419,-64.131 91.6419,-54.9743 91.6419,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.142,-46.4132 91.6419,-36.4133 88.142,-46.4133 95.142,-46.4132\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa202cc05d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2><h3>[info] Workflow 0d7769d2-5e2a-4ee5-95b2-7bc1713ee23d finished, state=Succeeded</h3><br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"e00ce5373e954c22a2f87e3cd46a38aa\"><a href=\"https://dashboard.default-tenant.app.vmdev94.lab.iguazeng.com/mlprojects/tutorial-dani/jobs/monitor/e00ce5373e954c22a2f87e3cd46a38aa/overview\" target=\"_blank\" >...d46a38aa</a></div></td>\n",
       "      <td>Dec 17 19:56:47</td>\n",
       "      <td>completed</td>\n",
       "      <td>auto-trainer-train</td>\n",
       "      <td><div class=\"dictlist\">model_class=sklearn.ensemble.RandomForestClassifier</div><div class=\"dictlist\">train_test_split_size=0.2</div><div class=\"dictlist\">label_columns=label</div><div class=\"dictlist\">model_name=cancer-classifier</div></td>\n",
       "      <td><div class=\"dictlist\">accuracy=0.9912280701754386</div><div class=\"dictlist\">f1_score=0.9919999999999999</div><div class=\"dictlist\">precision_score=0.9841269841269841</div><div class=\"dictlist\">recall_score=1.0</div></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td><div title=\"d7e2a3f64e2e466abd88e20abb51d992\"><a href=\"https://dashboard.default-tenant.app.vmdev94.lab.iguazeng.com/mlprojects/tutorial-dani/jobs/monitor/d7e2a3f64e2e466abd88e20abb51d992/overview\" target=\"_blank\" >...bb51d992</a></div></td>\n",
       "      <td>Dec 17 19:56:15</td>\n",
       "      <td>completed</td>\n",
       "      <td>get-data</td>\n",
       "      <td></td>\n",
       "      <td><div class=\"dictlist\">label_column=label</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the workflow\n",
    "run_id = project.run(\n",
    "    workflow_path=\"./workflow.py\",\n",
    "    arguments={\"model_name\": \"cancer-classifier\"}, \n",
    "    watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**View the pipeline in MLRun UI**\n",
    "\n",
    "![workflow](../_static/images/tutorial/workflow.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Run workflows using the CLI**\n",
    "\n",
    "With MLRun you can use a single command to load the code from local dir or remote archive (Git, zip, ..) and execute a pipeline. This can be very useful for integration with CI/CD frameworks and practices. See [CI/CD integration](https://docs.mlrun.org/en/latest/projects/ci-integration.html) for more details.\n",
    "\n",
    "The following command loads the project from the current dir (`.`) and executes the workflow with an argument, for running locally (without k8s).\n",
    "\n",
    "    mlrun project -r ./workflow.py -w -a model_name=classifier2 .!mlrun project -r ./workflow.py -w -a model_name=classifier2 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-model\"></a>\n",
    "## Test the deployed model endpoint\n",
    "\n",
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_fn = project.get_function(\"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2022-12-17 19:58:37,874 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-tutorial-dani-serving.default-tenant.svc.cluster.local:8080/v2/models/cancer-classifier/infer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '2a87a7a7-bddc-4293-a594-6d49c03f9259',\n",
       " 'model_name': 'cancer-classifier',\n",
       " 'outputs': [0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mock (simulator of the real-time function)\n",
    "my_data = {\"inputs\"\n",
    "           :[[\n",
    "               1.371e+01, 2.083e+01, 9.020e+01, 5.779e+02, 1.189e-01, 1.645e-01,\n",
    "               9.366e-02, 5.985e-02, 2.196e-01, 7.451e-02, 5.835e-01, 1.377e+00,\n",
    "               3.856e+00, 5.096e+01, 8.805e-03, 3.029e-02, 2.488e-02, 1.448e-02,\n",
    "               1.486e-02, 5.412e-03, 1.706e+01, 2.814e+01, 1.106e+02, 8.970e+02,\n",
    "               1.654e-01, 3.682e-01, 2.678e-01, 1.556e-01, 3.196e-01, 1.151e-01]\n",
    "            ]\n",
    "}\n",
    "serving_fn.invoke(\"/v2/models/cancer-classifier/infer\", body=my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Congratulations! You’ve completed Part 4 of the MLRun getting-started tutorial. To continue, proceed to [ Part 5 Model monitoring and drift detection](https://docs.mlrun.org/en/latest/tutorial/05-model-monitoring.html).\n",
    "\n",
    "You might also want to explore the following demos:\n",
    "\n",
    "- For an example of distributed training pipeline using TensorFlow, Keras, and PyTorch, see the [**mask detection demo**](https://github.com/mlrun/demos/tree/1.2.x/mask-detection).\n",
    "- To learn more about deploying live endpoints and concept drift, see the [**network-operations (NetOps) demo**](https://github.com/mlrun/demos/tree/1.2.x/network-operations).\n",
    "- To learn about using the feature store to process raw transactions and events in real-time and respond and block transactions before they occur, see the [**Fraud prevention demo**](https://github.com/mlrun/demos/tree/1.2.x/fraud-prevention-feature-store).  \n",
    "- For an example of a pipeline that summarizes and extracts keywords from a news article URL, see the [**News article summarization and keyword extraction via NLP**](https://github.com/mlrun/demos/tree/1.2.x/news-article-nlp)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
